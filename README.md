# MNIST Autoencoder using TensorFlow

## ğŸ“Œ Project Overview
This project implements a **Deep Autoencoder** using **TensorFlow and Keras** to learn **compressed representations (features)** of handwritten digit images from the **MNIST dataset**.

Unlike classification models, this project focuses on **unsupervised learning**, where the model learns patterns and structures in the data **without using labels**. The trained autoencoder reconstructs the original input images from a low-dimensional latent space.

---

## â“ What is an Autoencoder?
An **autoencoder** is a type of neural network designed to:
- Compress input data into a smaller representation (encoding)
- Reconstruct the original data from this compressed form (decoding)

It consists of:
- **Encoder** â†’ Feature extraction & compression
- **Latent Space** â†’ Compact representation of data
- **Decoder** â†’ Reconstruction of the original input

---

## ğŸ¯ Why This Project?
The goal of this project is to:
- Understand **unsupervised learning**
- Learn **feature extraction and dimensionality reduction**
- Demonstrate **image reconstruction**
- Explore how neural networks learn meaningful representations without labels

This project is useful for understanding the foundation of:
- Image compression
- Denoising
- Anomaly detection
- Representation learning

---

## ğŸ§  How the Project Works

### 1ï¸âƒ£ Dataset
- **MNIST Handwritten Digits**
- Image size: `28 Ã— 28`
- Grayscale images
- Labels are intentionally ignored

### 2ï¸âƒ£ Model Architecture

**Encoder:**
28Ã—28 â†’ 784 â†’ 128 â†’ 64 â†’ 32

**Decoder:**
32 â†’ 64 â†’ 128 â†’ 784 â†’ 28Ã—28

The latent space size is **32**
- Activation functions: ReLU (hidden layers), Sigmoid (output)
- Loss function: Binary Cross-Entropy
- Optimizer: Adam

---

## â–¶ï¸ How to Run the Project

### Step 1: Install Dependencies
pip install -r requirements.txt
Step 2: Run the Script
python mnist_autoencoder.py
